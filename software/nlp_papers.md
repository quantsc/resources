Hello!
This is a document with different seminal and (at the time of creation) cutting-edge papers geared around the topic of natural language processing.
These are all pulled fom a list of readings from Prof. Jesse Thomason's NLP class.
In general, the more "foundational" papers are generally the first 1-3, and the next 4-6 are less foundational, more just interesting.

Section 1
Logic and Conversation. Paul Grice. Syntax and Semantics 3: Speech Acts. Academic Press 1975.
Executing Instructions in Situated Collaborative Interactions. Alane Suhr, Claudia Yan, Jacob Schluger, Stanley Yu, Hadi Khader, Marwa Mouallem, Iris Zhang, Yoav Artzi. EMNLP 2019.
Vision-and-Dialog Navigation. Jesse Thomason, Michael Murray, Maya Cakmak, and Luke Zettlemoyer. CoRL 2019.
Collaborative dialogue in Minecraft. Anjali Narayan-Chen, Prashant Jayannavar, Julia Hockenmaier. ACL 2019.
TEACh: Task-driven Embodied Agents that Chat. Aishwarya Padmakumar, Jesse Thomason, Ayush Shrivastava, Patrick Lange, Anjali Narayan-Chen, Spandana Gella, Robinson Piramithu, Gokhan Tur, and Dilek Hakkani-Tur. AAAI 2022.
Recipes for building an open-domain chatbot. Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston. ArXiv, 2020.

Section 2
Efficient Estimation of Word Representations in Vector Space. Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean. ICLR 2013.
Deep contextualized word representations. Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer. NAACL 2018.
Attention Is All You Need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. NeurIPS 2017.
A Structured Vector Space Model for Word Meaning in Context. Katrin Erk and Sebastian Padó. EMNLP 2008.
ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks. Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox. CVPR 2020.
Grounding Language in Play. Corey Lynch and Pierre Sermanet. 2020.
Learning Language-Conditioned Robot Behavior from Offline Data and Crowd-Sourced Annotation. Suraj Nair and Eric Mitchell and Kevin Chen and Brian Ichter and Silvio Savarese and Chelsea Finn. CoRL 2021.

Section 3
The Curious Case of Neural Text Degeneration. Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi. International Conference on Learning Representations (ICLR), 2020.
Synthetic and Natural Noise Both Break Neural Machine Translation. Yonatan Belinkov, Yonatan Bisk. International Conference on Learning Representations (ICLR), 2018.
Distributed Representations of Words and Phrases and their Compositionality. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, Jeffrey Dean. Neural Information Processing Systems (NeurIPS) 2013.
Learning to Interpret Natural Language Navigation Instructions from Observations. David L. Chen and Raymond J. Mooney. AAAI 2011.
Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments. Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko Sünderhauf, Ian Reid, Stephen Gould, Anton van den Hengel. CVPR 2018.
Improving Vision-and-Language Navigation with Image-Text Pairs from the Web. Arjun Majumdar and Ayush Shrivastava and Stefan Lee and Peter Anderson and Devi Parikh and Dhruv Batra. ECCV 2020.
Shifting the Baseline: Single Modality Performance on Visual Navigation & QA. Jesse Thomason, Daniel Gordon, and Yonatan Bisk. North American Chapter of the Association for Computational Linguistics (NAACL), 2019.

Section 4
GloVe: Global Vectors for Word Representation. Jeffrey Pennington, Richard Socher, Christopher Manning. EMNLP 2014.
Sense Embedding Learning for Word Sense Induction. Linfeng Song, Zhiguo Wang, Haitao Mi, Daniel Gildea. *SEM 2016.
Enriching Word Vectors with Subword Information. Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov. TACL 2017.
VQA: Visual Question Answering. Stanislaw Antol and Aishwarya Agrawal and Jiasen Lu and Margaret Mitchell and Dhruv Batra and C. Lawrence Zitnick and Devi Parikh. ICCV 2015.
​​Information Maximizing Visual Question Generation. Ranjay Krishna and Michael Bernstein and Li Fei-Fei. CVPR 2019.
Grounded Situation Recognition. Sarah Pratt and Mark Yatskar and Luca Weihs and Ali Farhadi and Aniruddha Kembhavi. ECCV 2020.

Section 5
Entailment Semantics Can Be Extracted from an Ideal Language Model. William Merrill, Alex Warstadt, Tal Linzen. CoNLL 2022.
Multi-Modal Word Synset Induction. Jesse Thomason and Raymond J. Mooney. IJCAI 2017.
Does Pretraining for Summarization Require Knowledge Transfer? Kundan Krishna, Jeffrey Bigham, Zachary C. Lipton. EMNLP 2021.
Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering. Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen Gould, Lei Zhang. CVPR 2018.
Learning Transferable Visual Models From Natural Language Supervision. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever. 2021.
ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks. Jiasen Lu, Dhruv Batra, Devi Parikh, Stefan Lee. NeurIPS 2019.
ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision. Kim, Wonjae and Son, Bokyung and Kim, Ildoo. ICML 2021.
MERLOT: Multimodal Neural Script Knowledge Models. Rowan Zellers, Ximing Lu, Jack Hessel, Youngjae Yu, Jae Sung Park, Jize Cao, Ali Farhadi, Yejin Choi. NeurIPS 2021. 

Section 6
Is Reinforcement Learning (Not) for Natural Language Processing?: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization. Rajkumar Ramamurthy, Prithviraj Ammanabrolu, Kianté Brantley, Jack Hessel, Rafet Sifa, Christian Bauckhage, Hannaneh Hajishirzi, Yejin Choi. arXiv, 2022.
Downstream Datasets Make Surprisingly Good Pretraining Corpora. Kundan Krishna, Saurabh Garg, Jeffrey P. Bigham, Zachary C. Lipton. Arxiv 2022.
VIMA: General Robot Manipulation with Multimodal Prompts. Yunfan Jiang, Agrim Gupta, Zichen Zhang, Guanzhi Wang, Yongqiang Dou, Yanjun Chen, Li Fei-Fei, Anima Anandkumar, Yuke Zhu, Linxi Fan. arXiv, 2022.
https://larel-ws.github.io/accepted-papers/ [any paper you like from these proceedings]
PixL2R: Guiding Reinforcement Learning Using Natural Language by Mapping Pixels to Rewards. Prasoon Goyal, Scott Niekum, Raymond J. Mooney. 2020.
Inferring Rewards from Language in Context. Jessy Lin, Daniel Fried, Dan Klein, Anca Dragan. ACL 2022. 

Section 7
A New Path: Scaling Vision-and-Language Navigation with Synthetic Instructions and Imitation Learning. Aishwarya Kamath, Peter Anderson, Su Wang, Jing Yu Koh, Alexander Ku, Austin Waters, Yinfei Yang, Jason Baldridge, Zarana Parekh. arXiv, 2022.
Mapping Navigation Instructions to Continuous Control Actions with Position Visitation Prediction. Valts Blukis and Dipendra Misra and Ross A. Knepper and Yoav Artzi. CoRL 2018.
Sim-to-Real Transfer for Vision-and-Language Navigation. Peter Anderson and Ayush Shrivastava and Joanne Truong and Arjun Majumdar and Devi Parikh and Dhruv Batra and Stefan Lee. CoRL 2020.
Asking for Help Using Inverse Semantics. Stefanie Tellex and Ross Knepper and Adrian Li and Daniela Rus and Nicholas Roy. RSS 2014.
CLIPort: What and Where Pathways for Robotic Manipulation. Mohit Shridhar, Lucas Manuelli, Dieter Fox. CoRL 2021.
https://say-can.github.io/ [Post evolves faster than the paper, in this case.]

Section 8
Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data. Emily M. Bender and Alexander Koller. ACL 2020.
Experience Grounds Language. Yonatan Bisk, Ari Holtzman, Jesse Thomason, Jacob Andreas, Yoshua Bengio, Joyce Chai, Mirella Lapata, Angeliki Lazaridou, Jonathan May, Aleksandr Nisnevich, Nicolas Pinto, and Joseph Turian. EMNLP 2020.
The World of an Octopus: How Reporting Bias Influences a Language Model's Perception of Color. Cory Paik, Stéphane Aroca-Ouellette, Alessandro Roncone, Katharina Kann. EMNLP 2021.
Unnatural Language Processing: Bridging the Gap Between Synthetic and Natural Language Data. Alana Marzoev, Samuel Madden, M. Frans Kaashoek, Michael Cafarella, Jacob Andreas. 2020.
Towards Ecologically Valid Research on Language User Interfaces. Harm de Vries and Dzmitry Bahdanau and Christopher Manning. 2020.
